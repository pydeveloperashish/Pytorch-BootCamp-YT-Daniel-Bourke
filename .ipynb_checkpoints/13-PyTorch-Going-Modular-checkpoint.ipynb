{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0820136",
   "metadata": {},
   "source": [
    "# 1. Create Datasets and DataLoaders with a script `data_setup.py`\n",
    "\n",
    "Lets use the Jupyter magic function to create `.py` file for creating DataLoaders.\n",
    "\n",
    "We can save a code cell's contents to a file using Jupyter magic `%%writefile filename`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b984a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(), 'going_moduler')):\n",
    "    os.makedirs('going_moduler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11b3c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_moduler/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_moduler/data_setup.py\n",
    "\n",
    "\"\"\"\n",
    "Contains functionality for creating Pytorch DataLoader's for image classification data.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transform,\n",
    "    batch_size: int,\n",
    "    num_workers: int = NUM_WORKERS\n",
    "    ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates training and testing  DataLoaders.\n",
    "    \n",
    "    Takes in a training and testing directory path and turns them into\n",
    "    Pytorch Datasets and then into Pytorch DataLoaders.\n",
    "    \n",
    "    Args:\n",
    "        train_dir: Path to training dir.\n",
    "        test_dir: Path to testing dir.\n",
    "        transform: torchvision transforms to perform on training and testing data.\n",
    "        batch_size: no of Batch Size.\n",
    "        num_workers: workers per DataLoader. \n",
    "    \n",
    "    Returns:\n",
    "        A tuple of (trainn_dataloader, test_dataloader, class_names).\n",
    "        Where class_names is a list of the target classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Use ImageFolder to create datasets\n",
    "    train_data = datasets.ImageFolder(train_dir, transform = transform)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform = transform)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names  = train_data.classes\n",
    "    \n",
    "    # Turn images into DataLoaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = NUM_WORKERS,\n",
    "        pin_memory = True\n",
    "        )\n",
    "    \n",
    "    test_dataloader = DataLoader(\n",
    "        test_data,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = False,\n",
    "        num_workers = NUM_WORKERS,\n",
    "        pin_memory = True\n",
    "        )\n",
    "    \n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c8a21ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('Datasets/pizza_steak_sushi/train'),\n",
       " PosixPath('Datasets/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the train and test data dir.\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to a data folder\n",
    "data_path = Path(\"Datasets/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# Setup train and testing path\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path/ \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbde39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad27601d",
   "metadata": {},
   "source": [
    "# 2. Create a `transformations.py` file for transforms function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c2ea533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_moduler/transformations.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_moduler/transformations.py\n",
    "\n",
    "# Lets create transformations\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "def data_transform_function(img_size: int):\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize(size = (img_size, img_size)),\n",
    "        transforms.RandomHorizontalFlip(p = 0.5),\n",
    "        transforms.RandomVerticalFlip(p = 0.5),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    return data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df510a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd46b022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed763419",
   "metadata": {},
   "source": [
    "### Lets test the data_setup.py file and transformations.py we created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348e03c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fe12bef9520>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fe12bef94c0>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from going_moduler.data_setup import create_dataloaders\n",
    "from going_moduler.transformations import data_transform_function\n",
    "\n",
    "\n",
    "data_transform = data_transform_function(img_size = 64)\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = create_dataloaders(train_dir = train_dir,\n",
    "                                                                    test_dir = test_dir,\n",
    "                                                                    transform = data_transform,\n",
    "                                                                    batch_size = 4,\n",
    "                                                                    num_workers = os.cpu_count()\n",
    "                                                                    )\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed6340",
   "metadata": {},
   "source": [
    "### data_setup.py file and transformations.py files are working fine..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de87339e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10825dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a83ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd0a6cdc",
   "metadata": {},
   "source": [
    "# 3. Making a model (TinyVGG) with a script (`model_builder.py`)\n",
    "\n",
    "Let's turn our model building code into a Python Script we can import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "666685fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_moduler/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_moduler/model_builder.py\n",
    "\"\"\"\n",
    "Contains Pytorch model code to instantiate a TinyVGG model.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    def __init__(self, input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = input_shape, out_channels = hidden_units, kernel_size = 3,\n",
    "                      stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels = hidden_units, out_channels = hidden_units, kernel_size = 3,\n",
    "                      stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = hidden_units, out_channels = hidden_units, kernel_size = 3,\n",
    "                      stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels = hidden_units, out_channels = hidden_units, kernel_size = 3,\n",
    "                      stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features = hidden_units * 16 * 16,  # multiplying with shape of input images after conv_block_2\n",
    "                out_features = output_shape)\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv_block_2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        ## return self.classifier(self.conv_block_2(self.conv_block_1(x)))  # benifits from operator fusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd98504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev_ashish/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the model_builder.py script by forwarding a dummy data into the model.\n",
    "\n",
    "from going_moduler import model_builder\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "\n",
    "# Instantiate a model from the model_builder.py script\n",
    "torch.manual_seed(42)\n",
    "model_1 = model_builder.TinyVGG(input_shape = 3, hidden_units = 10, output_shape = len(class_names)).to(device)\n",
    "\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f752e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 64, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4, 3, 64, 64).to(device)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b488796b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ef0b5",
   "metadata": {},
   "source": [
    "### Model is working fine..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a29a25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3882add4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "467c36b2",
   "metadata": {},
   "source": [
    "# 4. Turn training functions into a script (`engine.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24fda780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_moduler/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_moduler/engine.py\n",
    "\n",
    "\"\"\"\n",
    "Contains functions for training and testing a Pytorch model.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# Create train_step() \n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device = \"cpu\"):\n",
    "    \n",
    "    model.train()     # Training Mode ON\n",
    "    \n",
    "    # Setup train loss and train accuracy values.\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Send data to the target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)    # outputs model logits\n",
    "        \n",
    "        # 2. Calculate the loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Loss Backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy metric\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim = 1), dim = 1)\n",
    "        train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n",
    "        \n",
    "    # Adjust metric to get average loss and accuracy per batch\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create test_step()\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               device = \"cpu\"):\n",
    "    \n",
    "    model.eval()    # Training Mode OFF, Eval Mode ON...\n",
    "    \n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Turn on inference mode\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Send data to the target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "            \n",
    "            # 2. Calculate the loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate the accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim = 1)\n",
    "            test_acc += (test_pred_labels == y).sum().item() / len(test_pred_labels)\n",
    "            \n",
    "        # Adjust metric to get average loss and average accuracy per batch\n",
    "        test_loss = test_loss / len(dataloader)\n",
    "        test_acc = test_acc / len(dataloader)\n",
    "        \n",
    "        return test_loss, test_acc\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# 1. Create a train function that takes in various model parameters + optimizers + dataloaders + loss_function.\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader,\n",
    "          test_dataloader,\n",
    "          optimizer,\n",
    "          loss_fn = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5,\n",
    "          device = \"cpu\"):\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": [] \n",
    "              }\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model = model,\n",
    "                                           dataloader = train_dataloader,\n",
    "                                           loss_fn = loss_fn,\n",
    "                                           optimizer = optimizer,\n",
    "                                           device = device)\n",
    "        \n",
    "        test_loss, test_acc = test_step(model = model,\n",
    "                                        dataloader = test_dataloader,\n",
    "                                        loss_fn = loss_fn,\n",
    "                                        device = device)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        print(f\"Epoch: {epoch} | Train Loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "    \n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1249a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666aa912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df30886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0c0b22f",
   "metadata": {},
   "source": [
    "# 5. Create a file called `utils.py` with utility functions\n",
    "\n",
    "\"utils\" in Python is generally reserved for various utility functions.\n",
    "Right now we only have one utility function (save_model()) but as our code grows we will likely have more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "183ca7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_moduler/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_moduler/utils.py\n",
    "\n",
    "\"\"\"\n",
    "File containing various utility functions for Pytorch model training.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "    \n",
    "    \"\"\"Saves a Pytorch model to a training directory\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create target directory\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents = True, exist_ok = True)\n",
    "    \n",
    "    # Create model save path\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model name should end with .pt or .pth\"\n",
    "        \n",
    "    model_save_path = os.path.join(target_dir_path, model_name)\n",
    "    \n",
    "    # Save the model state_dict()\n",
    "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "    torch.save(obj = model.state_dict(), f = model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb37cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a11c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148177f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ee94b4c",
   "metadata": {},
   "source": [
    "# 6. Create `train.py` to start the Training and Evaluate the model.\n",
    "\n",
    "Lets create a file called `train.py` to leverage all of our other code scripts to train a Pytorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a86ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_moduler/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_moduler/train.py\n",
    "\"\"\"\n",
    "Train a Pytorch image classification model...\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import transformations, data_setup, model_builder, engine, utils\n",
    "\n",
    "\n",
    "# 1. Define Constants\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 8\n",
    "HIDDEN_UNITS = 10\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "# 2. Setup directories\n",
    "train_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir, \"Datasets\", \"pizza_steak_sushi\", \"train\"))\n",
    "test_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir, \"Datasets\", \"pizza_steak_sushi\", \"test\"))\n",
    "\n",
    "\n",
    "# 3. Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"[INFO] Device: {device}\")\n",
    "\n",
    "\n",
    "# 4. Create transforms\n",
    "data_transform = transformations.data_transform_function(img_size = 64)\n",
    "\n",
    "\n",
    "# 5. Create Datasets, DataLoaders and get class_names\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir, \n",
    "                                                                               test_dir = test_dir,\n",
    "                                                                               transform = data_transform,\n",
    "                                                                               batch_size = BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Initialize Model\n",
    "model = model_builder.TinyVGG(input_shape = 3, \n",
    "                              hidden_units = HIDDEN_UNITS, \n",
    "                              output_shape = len(class_names)).to(device)\n",
    "\n",
    "\n",
    "# 6. Setup Loss and Optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n",
    "\n",
    "\n",
    "# 7. Start the training wuth help from engine.py\n",
    "engine.train(model = model,\n",
    "             train_dataloader = train_dataloader,\n",
    "             test_dataloader = test_dataloader,\n",
    "             loss_fn = loss_fn,\n",
    "             optimizer = optimizer,\n",
    "             epochs = NUM_EPOCHS,\n",
    "             device = device\n",
    "             )\n",
    "\n",
    "\n",
    "# 8. Save the trained model to file\n",
    "utils.save_model(model = model,\n",
    "                 target_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir, \"models\")),\n",
    "                 model_name = \"13_going_moduler_tiny_vgg_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa271a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d8de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b164d33",
   "metadata": {},
   "source": [
    "# 7. Going under `going_moduler` to run `train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "271ea2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/dev_ashish/DATA1/Python37/Projects/Python-Exercises/Pytorch-Tutorial/Pytorch-BootCamp-YT-Daniel Bourke/going_moduler\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"going_moduler\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db5dbfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dev_ashish/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "[INFO] Device: cpu\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]Epoch: 0 | Train Loss: 1.1078 | Train acc: 0.3017 | Test Loss: 1.0980 | Test Acc: 0.3625\n",
      " 33%|███████████████                              | 1/3 [00:01<00:02,  1.04s/it]Epoch: 1 | Train Loss: 1.0654 | Train acc: 0.4181 | Test Loss: 1.0549 | Test Acc: 0.4125\n",
      " 67%|██████████████████████████████               | 2/3 [00:02<00:00,  1.00it/s]Epoch: 2 | Train Loss: 1.0018 | Train acc: 0.4871 | Test Loss: 0.9834 | Test Acc: 0.4667\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:02<00:00,  1.01it/s]\n",
      "[INFO] Saving model to: /media/dev_ashish/DATA1/Python37/Projects/Python-Exercises/Pytorch-Tutorial/Pytorch-BootCamp-YT-Daniel Bourke/models/13_going_moduler_tiny_vgg_model.pth\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86a5747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc9f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a91d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2956a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1cf3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd0fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2573014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a45f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f87eaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eaaea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e130f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
